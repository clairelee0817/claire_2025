{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: Understanding Computer Bias\n",
    "permalink: /understandingcomputerbias/\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is computer Bias?\n",
    "It's unfair preferences built into a computer system. Often, the bias isn't deliberate, but a result from designing, testing, and using. \n",
    "\n",
    "EX: \n",
    "- Data Issues: a system may perform poorly for a certain demographic that it doesn't have enough data on\n",
    "- Design Choices: designers may assume that users will use their system in similar ways without considering other uses\n",
    "- Testing Gaps: in testing phases, there may be limited research so that only a small fraction of the entire population is assessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popcorn Hack #1\n",
    "\n",
    "An example of a TV show that demonstrates bias is *Law and Order: SVU*, which can be seen as a TV show in favor of the police force since it portrays their everyday lives as interesting and just (aka copaganda)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everyday Exammples of Bias\n",
    "- Netflix Rec.: suggests movies/shows \n",
    "- Virtual Assistants with Female Voices: most AI voices are female\n",
    "- Social Media Age Gaps: TikTok vs. Facebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popcorn Hack #2\n",
    "\n",
    "I downloaded an app called Foodvisor with the intention in trying to start a habit of calorie tracking for my diet. It was initially helpful and helped me realize that my diet wasn't healthy, but it had a very limited database of food. Since I'm Korean and mostly eat Korean food, I struggled to find a lot of the foods that I ate in their database, and often had to insert them myself or use an unofficial item that another user had added. This frustrated me and made me wonder if all other calorie tracking apps would be like this and whether there was a bias towards non-Asian demographics within the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The HP Camera Incident\n",
    "\n",
    "The HP camera was able to follow light-skinned faces with ease, but struggled with dark-skinned faces. It was unintetional, but people accused it of being racist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding Bias in Tech\n",
    "- Expand your data\n",
    "- Encourage diverse teams\n",
    "- Test, test, test\n",
    "- Dcoumument your assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popcorn Hack #3\n",
    "\n",
    "While designing a fitness tracking app, there may be a bias in evaluating performances based on age. Since more young people perform fitness better than old people, the app may evaluate an old person's workout as poor depending on the mass assumption of higher expectations from young people. To help with this, the app should have specific parameters that evaluate the person's workout considering their age and what's average for their age as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why It All Matters\n",
    "- Exclude people\n",
    "- Reinforce negative stereotypes\n",
    "- Limit choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework Hack #1\n",
    "\n",
    "1. TikTok\n",
    "2. **Identifying Potential Bias**: When users choose to post, often, the TikTok algorithm will recommend some posts over others (e.g. a person in need bring awareness will most likely be less recommended than a popular influencer).\n",
    "3. **Analyze the Cause**: The TikTok algorithm (the For You page) analyzes a user's interactions/frequent watches and assesses what to recommend and whether or not to include new recommendations. Due to this, if a user were disinterested/unaware of a person trying to ask for help online, the chances that the algorithm will bring that video towards them is slimmer than bringing an influencer that is related to the user's interests. \n",
    "4. **Propose a Solution**: To fix this, the algorithm can be designed to add a specific page such as the For You page that is dedicated to global issues, so that user interactions are less considered and dire situations are brought to light. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
